{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a6299a",
   "metadata": {},
   "source": [
    "<strong>\n",
    "    <font color=\"#0E1117\">\n",
    "        Author: lprtk\n",
    "    </font>\n",
    "</strong>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<Center>\n",
    "    <h1 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            NLP: exploring HuggingFace Transformers\n",
    "        </font>\n",
    "    </h1>\n",
    "</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a88c74",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12b795",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Introduction & context\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad6710",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "    This notebook focuses on exploring and testing how we can use a simple pre-trained Transformers language model for different Natural Language Processing (NLP) tasks with Python. The objective is to extract information and value from large volumes of textual data using NLP.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974a388",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd7279",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Librairies import\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8fed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f2075",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f48c2",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Sentiment analysis & scoring\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbce209",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Data\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"I love flying Air New Zealand because they have the best food!\",\n",
    "    \"That orange Fiat Multipla is the ugliest car Iâ€™ve ever seen.\",\n",
    "    \"I love this phone but wouldnâ€™t recommend it to my friends.\",\n",
    "    \"I have just broken down with my motorcycle, I AM MISTAKEN...\",\n",
    "    \"Data Scientist must to have several skills: statistics, IT and business expertise.\",\n",
    "    \"I'm happy because I'll be able to sunbathe under the coconut trees ðŸ˜‚.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebca88f",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Model\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a9f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer = pipeline(task=\"text-classification\", model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbf05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(sentiment_analyzer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b89577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.663035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.973586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.868442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  POSITIVE  0.999876\n",
       "1  NEGATIVE  0.663035\n",
       "2  POSITIVE  0.973586\n",
       "3  NEGATIVE  0.999557\n",
       "4  POSITIVE  0.868442\n",
       "5  POSITIVE  0.999863"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a019df1",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecadefb",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Named entity recognition\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82bfbf",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Data\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec34df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Microsoft has announced the launch of a student program to build ai skills. The Redmond \n",
    "giant wants to expand its reach and plans to build a strong developer ecosystem between \n",
    "India and the US. The company will provide tools and services such as Microsoft Cognitive \n",
    "Services, Bot Services and Azure Machine Learning. Manish Prakash, general manager, Microsoft \n",
    "India, said, \"ai being the defining technology of our time is transforming lives and industry \n",
    "and the jobs of tomorrow will require different skills.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5d666d",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Model\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4efb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
      "Some layers from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing TFBertForTokenClassification: ['dropout_147']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "ner_analyzer = pipeline(task=\"ner\", aggregation_strategy=\"simple\", model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb73153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(ner_analyzer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa67f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.706997</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>81</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>India</td>\n",
       "      <td>179</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>US</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>Microsoft Cognitive Services</td>\n",
       "      <td>249</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.987963</td>\n",
       "      <td>Bot Services</td>\n",
       "      <td>280</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.991273</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>297</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>Manish Prakash</td>\n",
       "      <td>321</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.978427</td>\n",
       "      <td>Microsoft India</td>\n",
       "      <td>354</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score                          word  start  end\n",
       "0          ORG  0.999610                     Microsoft      1   10\n",
       "1          ORG  0.706997                       Redmond     81   88\n",
       "2          LOC  0.999741                         India    179  184\n",
       "3          LOC  0.999685                            US    193  195\n",
       "4          ORG  0.993000  Microsoft Cognitive Services    249  278\n",
       "5          ORG  0.987963                  Bot Services    280  292\n",
       "6          ORG  0.991273        Azure Machine Learning    297  319\n",
       "7          PER  0.999419                Manish Prakash    321  335\n",
       "8          ORG  0.978427               Microsoft India    354  370"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d76f8",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc277f63",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Question answering\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc782e6a",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Data\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc3b29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The phone is in good condition and well protected in the packaging. I also bought \n",
    "a shell for my phone hoping it would fit, but it did not. It is a shell for the old \n",
    "model which explains the low price. Thanks to Amazon for shipping this product to \n",
    "France with Prime. I hope they will add more products under Prime to ship from the \n",
    "US to France. The prices and collection of items are still not good on the France site, \n",
    "and are nowhere near the same level as the US site. Thanks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aa8417",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Model\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9983a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n",
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_113']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(task=\"question-answering\", model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4916aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is the customer satisfied?\"\n",
    "df_result = pd.DataFrame([question_answerer(question=question, context=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2c4f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063303</td>\n",
       "      <td>130</td>\n",
       "      <td>140</td>\n",
       "      <td>it did not</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end      answer\n",
       "0  0.063303    130  140  it did not"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a84b233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Why the customer is not satisfied?\"\n",
    "df_result = pd.DataFrame([question_answerer(question=question, context=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b04fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036813</td>\n",
       "      <td>142</td>\n",
       "      <td>174</td>\n",
       "      <td>It is a shell for the old \\nmodel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                             answer\n",
       "0  0.036813    142  174  It is a shell for the old \\nmodel"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332a6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to improve customer satisfaction?\"\n",
    "df_result = pd.DataFrame([question_answerer(question=question, context=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0e4a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00833</td>\n",
       "      <td>278</td>\n",
       "      <td>348</td>\n",
       "      <td>they will add more products under Prime to shi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score  start  end                                             answer\n",
       "0  0.00833    278  348  they will add more products under Prime to shi..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003a8d3",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd5936",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Text summarization\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773a2c8",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Data\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad1eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "For years, Facebook gave some of the world's largest technology companies more intrusive \n",
    "access to users' personal data than it has disclosed, effectively exempting those business \n",
    "partners from its usual privacy rules, according to internal records and interviews. The \n",
    "special arrangements are detailed in hundreds of pages of Facebook documents obtained by \n",
    "The New York Times. The records, generated in 2017 by the company's internal system for \n",
    "tracking partnerships, provide the most complete picture yet of the social network's \n",
    "data-sharing practices. They also underscore how personal data has become the most prized \n",
    "commodity of the digital age, traded on a vast scale by some of the most powerful companies \n",
    "in Silicon Valley and beyond. The exchange was intended to benefit everyone. Pushing for \n",
    "explosive growth, Facebook got more users, lifting its advertising revenue. Partner companies \n",
    "acquired features to make their products more attractive. Facebook users connected with friends \n",
    "across different devices and websites. But Facebook also assumed extraordinary power over the \n",
    "personal information of its 2 billion users - control it has wielded with little transparency \n",
    "or outside oversight.Facebook allowed Microsoft's Bing search engine to see the names of virtually \n",
    "all Facebook user's friends without consent, the records show, and gave Netflix and Spotify the \n",
    "ability to read Facebook users' private messages.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc9cba",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Model\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c34d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small (https://huggingface.co/t5-small)\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "C:\\Lucas_M1\\Anaconda\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_summarizer = pipeline(task=\"summarization\", model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6294c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = text_summarizer(text, max_length=50, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f494d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal data has become the most prized commodity of the digital age, traded on a vast scale by some of the most powerful companies in Silicon Valley and beyond. the exchange was intended to benefit everyone, pushing for explosive growth.\n"
     ]
    }
   ],
   "source": [
    "print(result[0][\"summary_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
